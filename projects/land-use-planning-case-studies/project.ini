
[type Impact]
type.Reinstatement_Cost = integer
type.Life_Safety_Risk = floating
type.Displacement_Days = integer
type.Damage_Ratio = floating
type.Depth = floating

[type building]
type.Reinstatement_Cost = floating
type.Use_Category = text
type.Storeys = integer

[function flood_building_impact]
location = functions/flood_building.py
argument-types = [building, depth: nullable(floating)]
return-type = Impact

[type Road_Impact]
type.Fix_Time_Days = integer
type.Fix_Cost = integer
type.Damage_Ratio = floating
type.Disruption = integer
type.Depth = floating
type.Unmitigated_Depth = floating
type.Exposed_Length = floating

[type Road_Exposure]
type.length = floating
type.depth = floating
type.unmitigated_depth = floating
type.coastal_energy = text

[function flood_road_impact]
location = functions/coastal_flood_road.py
argument-types = [exposed_road: Road_Exposure]
return-type = Road_Impact

[function assign_construction_year]
location = functions/building_year.py
argument-types = [seed: floating, max_year: integer, intensification_factor: floating]
return-type = integer

[bookmark coastal_hazard_maps]
location = coastal_hazard_maps.csv
set-attribute.eventid = return_period + 'yr'
# this bit turns the location in to a coverage which we can spatially query
set-attribute.coverage = bookmark(id: file, options: {}, type: 'coverage(floating)')
set-attribute.Exceedance_Probability =  1 - exp(0 - (1/float(return_period)))
set-attribute.Return_Period = int(return_period)
set-attribute.SLR = int(SLR)

[bookmark CS1_hazard_maps]
location = CS1_hazard_maps.csv
set-attribute.eventid = return_period + 'yr'
# this bit turns the location in to a coverage which we can spatially query
set-attribute.coverage = bookmark(id: file, options: {}, type: 'coverage(floating)')
set-attribute.Exceedance_Probability =  1 - exp(0 - (1/float(return_period)))
set-attribute.Return_Period = int(return_period)

[bookmark CS1_test_hazard]
description = Hazard maps for testing CS1 model (because we cannot access the actual hazard data)
location = coastal_hazard_maps.csv
set-attribute.eventid = return_period + 'yr'
# this bit turns the location in to a coverage which we can spatially query
set-attribute.coverage = bookmark(id: file, options: {}, type: 'coverage(floating)')
set-attribute.Exceedance_Probability =  1 - exp(0 - (1/float(return_period)))
set-attribute.Return_Period = int(return_period)
filter = SLR = '0'

[bookmark CS1_current_buildings_orig]
location = exposures/CS1_buildings_zones.geojson
set-attribute.Storeys = ceil(Storeys)
set-attribute.id = Outline_id
set-attribute.Use_Category = Use_Catego
set-attribute.Reinstatement_Cost = Rep_Cost
# NB: Age may be zero for some buildings but that shouldn't matter here
set-attribute.Construction_Year = Age
set-attribute.Floor_Height = Floor_Heig

[bookmark CS1_current_buildings]
location = exposures/CS1_current_buildings.gpkg
# float -> int conversion for construction year
set-attribute.Construction_Year = round(Construction_Year)

[bookmark CS1_future_buildings]
# TODO update with future building layer for Oakley Creek
location = exposures/future-buildings.gpkg
set-attribute.Floor_Height = 0.2

[bookmark buildings]
location = exposures/orewa_buildings.geojson
crs-name = EPSG:2193
crs-longitude-first = true
set-attribute.Use_Category = Use_Catego
set-attribute.Reinstatement_Cost = Rep_Cost
# Year doesn't really matter for these buildings, as long as it's in the past
set-attribute.Construction_Year = 2000

[bookmark current-buildings]
location = exposures/orewa_buildings.gpkg
set-attribute.Storeys = ceil(Storeys)
set-attribute.id = Outline_id
set-attribute.Floor_Height = Floor_Heig

[bookmark Orewa_Zones]
location = exposures/AC_UP_BaseZone_Orewa.geojson
crs-name = EPSG:2193
crs-longitude-first = true

[bookmark future-buildings]
location = exposures/exposure_future_orewa_test_attributes.geojson
crs-name = EPSG:2193
crs-longitude-first = true
set-attribute.Use_Category = Use_Catego
set-attribute.Reinstatement_Cost = Rep_Cost
set-attribute.ID = id

[bookmark none]
location = exposures/none.gpkg
crs-name = EPSG:4326
crs-longitude-first = true

[model CS4-Orewa]
description = Case Study 4: Climate Change Interventions
location = building-pipeline.txt
framework = pipeline
param.years = [2005, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100, 2110, 2120]
param.return_periods = [ 2, 5, 10, 20, 50, 100, 200, 500, 1000 ]
param.SLRs = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]
param.current_buildings = 'current-buildings'
param.future_buildings = 'exposures/future-buildings.gpkg'
param.hazard_maps = 'coastal_hazard_maps'
param.cc_projection = 'data_export_site747_geodata_nz_sea_rise_national_projections_and_vlm_readings.csv'
# this is just which attribute to use from the CSV file as the SLR
param.projected_SLR = p50
# this just filters the CC CSV file by the scenario of interest
param.scenario = 'SSP2-4.5 (medium confidence)'
# this controls how long you want to simulate new development up to
param.max_year = 2120
# unlikely, but going back any earlier than 2005 would break things
param.max_year.properties = min: 2005, integer
# this is also hard-coded into the Python function, but we do it in the pipeline
# because of how we interpolate the losses
param.min_depth = 0.05
# dial up or the percentage of new buildings that actually get constructed
param.percent_future_buildings = 0
# output the building dataset at various points of the model
# the year values should line up with the years in the cc_projection CSV file
param.snapshot_year1 = -1
param.snapshot_year2= -1
param.snapshot_year3 = -1
param.snapshot_year4 = -1
# exposure.ID makes the randomness reproducible. To make it truly random,
# change this to: random_uniform(minint(), maxint())
param.random_seed = exposure.id
param.aggregation_layer = 'Orewa_Zones'
param.no_intensification = 'none'
param.retreat = 'none'
# same as max_year for construction, but it removes all designated buildings by that date
param.retreat_by = 2120

[model CS3-Maraetai]
description = Case Study 3: Dynamic Adaptive Policy Pathways (DAPP)
location = road-pipeline.txt
framework = pipeline
param.years = [2005, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100, 2110, 2120]
param.SLRs = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]
param.max_year = 2120
param.cc_projection = 'data_export_site747_geodata_nz_sea_rise_national_projections_and_vlm_readings.csv'
# this is just which attribute to use from the CSV file as the SLR
param.projected_SLR = p50
# this just filters the CC CSV file by the scenario of interest
param.scenario = 'SSP2-4.5 (medium confidence)'
param.roads = 'exposures/maraetai_road.shp'
param.hazard_maps = 'coastal_hazard_maps'
param.metric_crs = 'EPSG:2193'
param.seawall_height = 0
param.min_depth = 0.01
# can change this to mean(hazard), percentile(hazard,90) etc
param.aggregate_hazard = max(hazard)
param.coastal_energy = 'low'

[model CS1-Oakley]
location = policy-interventions-pipeline.txt
framework = pipeline
param.current_buildings = 'CS1_current_buildings'
param.future_buildings = 'CS1_future_buildings'
param.hazard_maps = 'CS1_hazard_maps'
param.aggregation_layer = 'Orewa_Zones'
# by default, use whatever floor height is baked into the exposure-layer
param.min_floor_height_m = exposure.Floor_Height
param.flood_level_RP = 100
param.freeboard_mm = null_of('integer')
param.mitigate_buildings = 'all'
param.years = [2023, 2060, 2085, 2120]
# output the building dataset at various points of the model
param.snapshot_year1 = -1
param.snapshot_year2= -1
param.snapshot_year3 = -1
param.snapshot_year4 = -1
param.max_year = 2120
# unlikely, but going back any earlier than 2005 would break things
param.max_year.properties = min: 2005, integer
# dial up or the percentage of new buildings that actually get constructed
param.percent_future_buildings = 0
# exposure.ID makes the randomness reproducible. To make it truly random,
# change this to: random_uniform(minint(), maxint())
param.random_seed = exposure.id
param.no_intensification = 'none'
param.retreat = 'none'
# same as max_year for construction, but it removes all designated buildings by that date
param.retreat_by = 2120

[bookmark Drury_zones]
location = data/CS2/drury_FUZ.geojson
crs-name = EPSG:2193
crs-longitude-first = true

[bookmark Auckland_faults_buffered]
location = data/CS2/auckland_faults_buffer_250m.geojson
crs-name = EPSG:2193
crs-longitude-first = true

[bookmark GNS_observed_landslides]
location = data/CS2/gns_observed_landslides.geojson
crs-name = EPSG:2193
crs-longitude-first = true

[model CS2-Drury]
location = risk-identification-pipeline.txt
framework = pipeline
param.development_zones = 'Drury_zones'
# 50m x 50m = 2500m2
param.grid_size_m = 50
param.faults = 'Auckland_faults_buffered'
param.faults_weight = 1.0
param.observed_landslides = 'GNS_observed_landslides'
param.observed_landslides_weight = 1.0
param.liquefaction = 'data/CS2/liq_hazard.shp'
param.liquefaction_threshold = 3
param.liquefaction_weight = 1.0
param.LSL = 'data/CS2/lsl_grid.tif'
param.LSL_threshold = 3
param.LSL_weight = 1.0
param.evacuation_zone = 'data/CS2/MASTER_EM_EvacuationZone.shp'
param.evacuation_zone_weight = 1.0
param.flood = 'data/CS2/regional_flood_drury.tif'
param.flood_threshold = 0.05
param.flood_weight = 1.0

